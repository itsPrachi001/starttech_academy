{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsPrachi001/starttech_academy/blob/master/task_4_dl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVARtMOJ29-l",
        "outputId": "990956d8-6523-4f20-84cf-aa39edb892e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model, Model, Sequential\n",
        "import cv2,os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path='/content/drive/MyDrive/Osteoarthritis_Assignment_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0jaqV3UOnav"
      },
      "outputs": [],
      "source": [
        "IMG_height = 224\n",
        "IMG_width = 224\n",
        "val_path=r'/content/drive/MyDrive/Osteoarthritis_Assignment_dataset/Valid'\n",
        "test_path=r'/content/drive/MyDrive/Osteoarthritis_Assignment_dataset/test'\n",
        "train_path=r'/content/drive/MyDrive/Osteoarthritis_Assignment_dataset/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51KXSyu2PFru",
        "outputId": "f8160942-d0e1-44b3-9214-68cf71618232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes :  ['Osteoarthritis', 'Normal']\n",
            "Number of training images : 2350\n",
            "Number of validation images : 641\n"
          ]
        }
      ],
      "source": [
        "classes = os.listdir(train_path)\n",
        "\n",
        "# Counting total number of images for training and valdation\n",
        "num_train = len(glob(train_path + '/*/*'))\n",
        "num_val = len(glob(val_path + '/*/*'))\n",
        "print('Classes : ', classes)\n",
        "print(f'Number of training images : {num_train}\\nNumber of validation images : {num_val}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbUE7EN5PQP1"
      },
      "outputs": [],
      "source": [
        "# Loading images from image paths\n",
        "def parse_image(file_path):\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_png(image, channels=1)\n",
        "    image = tf.image.resize(image, [IMG_height, IMG_width])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuEym9ESPTWe"
      },
      "outputs": [],
      "source": [
        "def make_dataset(path, batch_size):\n",
        "    \n",
        "    # Collecting all filepath in a directory\n",
        "    filenames = glob(path + '/*/*')\n",
        "    # Shuffling the dataset\n",
        "    random.shuffle(filenames)\n",
        "    # Extraction labels from fil paths(as numbers Normal:0, Osteoarthritis:1)\n",
        "    labels = [classes.index(name.split(os.path.sep)[-2]) for name in filenames]\n",
        "\n",
        "    # Creating instance of tf.data.dataset from filenames\n",
        "    filenames_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
        "    # loading files\n",
        "    images_ds = filenames_ds.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    images_ds = tf.data.Dataset.zip((images_ds, labels_ds))\n",
        "    images_ds = images_ds.shuffle(buffer_size=100)\n",
        "    images_ds = images_ds.batch(batch_size)\n",
        "    images_ds = images_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return images_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuIQxZuKPaFX",
        "outputId": "285f3bda-6e85-46ee-9631-fd599f730c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 342 ms, sys: 25.9 ms, total: 368 ms\n",
            "Wall time: 721 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "ds_train = make_dataset(train_path, 32)\n",
        "ds_val = make_dataset(train_path, 32)\n",
        "ds_test = make_dataset(train_path, 128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD4_taFpPhdp"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        # Stop training when `val_loss` is no longer improving\n",
        "        monitor=\"val_loss\",\n",
        "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
        "        min_delta=1e-2,\n",
        "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VCR2qi2Pkh3"
      },
      "outputs": [],
      "source": [
        "def build_model_A():\n",
        "    batch_size = 32\n",
        "    num_classes = 2\n",
        "\n",
        "    i = Input(shape=(224, 224, 1))\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Hidden layer\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # last hidden layer i.e.. output layer\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(i, x)\n",
        "\n",
        "    # model description\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(3e-4),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I__2EKd8P41O",
        "outputId": "23206403-a2ca-4d10-bd23-6d9083d3635d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 224, 224, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 32)      9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 224, 224, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 112, 112, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 112, 112, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 56, 56, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 56, 56, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               51380736  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,669,986\n",
            "Trainable params: 51,669,090\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 224, 224, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 32)      9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 224, 224, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 112, 112, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 112, 112, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 56, 56, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 56, 56, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               51380736  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,669,986\n",
            "Trainable params: 51,669,090\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = build_model_A()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KLY10cRP7wy",
        "outputId": "2053e8b2-5b3e-454d-dae2-86a52eec47db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "74/74 [==============================] - 2555s 35s/step - loss: 2.4237 - accuracy: 0.7353 - val_loss: 38.2316 - val_accuracy: 0.3452\n",
            "Epoch 2/20\n",
            "74/74 [==============================] - 985s 13s/step - loss: 0.3964 - accuracy: 0.8200 - val_loss: 48.3506 - val_accuracy: 0.3393\n",
            "Epoch 3/20\n",
            "74/74 [==============================] - 981s 13s/step - loss: 0.2811 - accuracy: 0.8809 - val_loss: 36.1175 - val_accuracy: 0.3467\n",
            "Epoch 4/20\n",
            "74/74 [==============================] - 981s 13s/step - loss: 0.2137 - accuracy: 0.9089 - val_loss: 27.1861 - val_accuracy: 0.3363\n",
            "Epoch 5/20\n",
            "74/74 [==============================] - 984s 13s/step - loss: 0.2234 - accuracy: 0.9123 - val_loss: 15.3418 - val_accuracy: 0.3676\n",
            "Epoch 6/20\n",
            "74/74 [==============================] - 992s 13s/step - loss: 0.1647 - accuracy: 0.9311 - val_loss: 4.4945 - val_accuracy: 0.6726\n",
            "Epoch 7/20\n",
            "74/74 [==============================] - 1005s 14s/step - loss: 0.1025 - accuracy: 0.9591 - val_loss: 4.5634 - val_accuracy: 0.7173\n",
            "Epoch 8/20\n",
            "74/74 [==============================] - 1003s 14s/step - loss: 0.1084 - accuracy: 0.9600 - val_loss: 1.9629 - val_accuracy: 0.8244\n",
            "Epoch 9/20\n",
            "74/74 [==============================] - 1003s 14s/step - loss: 0.1185 - accuracy: 0.9553 - val_loss: 0.1765 - val_accuracy: 0.9256\n",
            "Epoch 10/20\n",
            "74/74 [==============================] - 1009s 14s/step - loss: 0.0868 - accuracy: 0.9647 - val_loss: 0.1058 - val_accuracy: 0.9539\n",
            "Epoch 11/20\n",
            "74/74 [==============================] - 1004s 14s/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.0410 - val_accuracy: 0.9851\n",
            "Epoch 12/20\n",
            "74/74 [==============================] - 1015s 14s/step - loss: 0.0346 - accuracy: 0.9868 - val_loss: 0.0621 - val_accuracy: 0.9777\n",
            "Epoch 13/20\n",
            "74/74 [==============================] - 1008s 14s/step - loss: 0.0549 - accuracy: 0.9783 - val_loss: 0.0450 - val_accuracy: 0.9777\n",
            "Epoch 14/20\n",
            "74/74 [==============================] - 1019s 14s/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.0151 - val_accuracy: 0.9940\n",
            "Epoch 15/20\n",
            "74/74 [==============================] - 1014s 14s/step - loss: 0.0297 - accuracy: 0.9885 - val_loss: 0.1042 - val_accuracy: 0.9509\n",
            "Epoch 16/20\n",
            "74/74 [==============================] - 1015s 14s/step - loss: 0.0490 - accuracy: 0.9838 - val_loss: 0.1791 - val_accuracy: 0.9435\n",
            "Epoch 17/20\n",
            "74/74 [==============================] - 1028s 14s/step - loss: 0.0833 - accuracy: 0.9638 - val_loss: 0.0424 - val_accuracy: 0.9836\n",
            "Epoch 18/20\n",
            "74/74 [==============================] - 1010s 14s/step - loss: 0.0576 - accuracy: 0.9762 - val_loss: 0.0397 - val_accuracy: 0.9836\n",
            "Epoch 19/20\n",
            "74/74 [==============================] - 1018s 14s/step - loss: 0.0510 - accuracy: 0.9813 - val_loss: 0.0251 - val_accuracy: 0.9881\n",
            "Epoch 19: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f85c12bfe10>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# training model\n",
        "model.fit(ds_train, epochs=20, steps_per_epoch=math.ceil(num_train/32), \n",
        "          verbose=1, callbacks=callbacks, validation_data=ds_val,\n",
        "         validation_steps=math.ceil(num_val/32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqdOZkFzRKvJ"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2rmyNnNQBG7"
      },
      "outputs": [],
      "source": [
        "# evaluating model\n",
        "model.evaluate(ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmnK6NGXQFW4"
      },
      "outputs": [],
      "source": [
        "# saving model\n",
        "model.save('Osteoarthritis_Classifier.model', save_format='h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "task_4_dl.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbjqSuSM3m3ecq1+R4I5WK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}